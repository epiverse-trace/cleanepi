---
title: "cleanepi"
output: 
  rmarkdown::html_vignette:
    df_print: "kable"
vignette: >
  %\VignetteIndexEntry{cleanepi}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE} 
knitr::opts_chunk[["set"]](collapse = TRUE, comment = "#>", eval = FALSE,
                           fig.width = 7L, fig.height = 7L,
                           fig.align = "center")
row_id <- group_id <- NULL
```


## An overview

No matter how many measures are taken, one must always expect messy data from the real-world, with duplicates, errors, incomplete, or irrelevant formats. Data cleaning is an essential step in data analysis. It allows to produce accurate, reliable and reproducible results. However, data cleaning is a significant barrier in data analysis because it takes a long time to complete.

**{cleanepi}** is an R package to clean, curate, and standardize epidemiological data. It contains functions to perform several data cleaning tasks that an end-user would anticipate to be performed on a cluttered dataset.

**{cleanepi}** is specifically designed for epidemiological data, and works with data frame-like data structure. This vignette provides a detailed description of the functions included in the package and how to use them.

```{r setup, eval=TRUE}
library("cleanepi")
library("magrittr")
```

## General data cleaning tasks

The main function in **{cleanepi}** is `clean_data()` that can perform the following tasks:

1. Scan the input data to determine the percent of missing, numeric, character, logical and date values in every column of the input data frame.   
2. Clean up column names and convert them to more sensible formats. This includes many sub-tasks such as changing a space, dot, or hyphen between two words with underscore; converting camel-cases to snake-cases; substituting foreign characters with their corresponding English characters; and splitting a long word into multiple short words by capital characters within, if any, and connecting them with underscores.   
3. Remove duplicated rows (across all columns or some specific columns). This also includes the removal of empty rows and columns as well as constant columns, i.e. columns with the same value across all rows.   
4. Replace missing entries with `NA`. 
5. Check whether the the sequence of date events are correct in all rows of the input data.
6. Convert `character` columns into `Date` if the column actually contains values of type `Date` to some extent (default is 50% of the values are `Date`).
7. Detect and remove rows with subject IDs that do not comply with the expected format.
8. Perform dictionary-based cleaning: replace keys in specific columns with their corresponding values stored in a data dictionary file, replace misspelled values with their correct ones.
9. Convert numbers written in characters into numeric.

Every cleaning operation in **{cleanepi}** is implemented as a module. These modules are described in details in the package design vignette.

```{r eval=TRUE, comment="read_input"}
# IMPORTING THE TEST DATASET
test_data <- readRDS(system.file("extdata", "test_df.RDS",
                                 package = "cleanepi"))
head(test_data)
```

```{r eval=TRUE, comment="scan_data"}
# SCAN THE DATA
scan_result <- scan_data(test_data)
print(scan_result)
```

```{r eval=TRUE}
# DEFINING THE DATA CLEANING PARAMETERS
params <- list(
  keep                = "date.of.admission",
  remove_duplicates   = TRUE,
  target_columns      = NULL,
  replace_missing     = TRUE,
  na_comes_as         = "-99",
  check_timeframe     = TRUE,
  timeframe           = as.Date(c("1973-05-29", "2023-05-29")),
  error_tolerance     = 0.5,
  subject_id_col_name = "study_id",
  subject_id_format   = "PS000P2",
  prefix              = "PS",
  suffix              = "P2",
  range               = c(1L, 100L),
  dictionary          = test_dictionary
)
```

The `clean_data()` function expects 2 arguments:

1. **data**: the input data frame or linelist
2. **params**: a list of parameters that define which cleaning operations will
    be performed.

```{r eval=TRUE, comment="run_clean_data"}
# CLEAN THE INPUT DATA FRAME
cleaned_data <- clean_data(
  data   = test_data,
  params = params
)
```

It returns the cleaned dataset. The report generated from the data cleaning
operations is a `list object` that is attached to the cleaned data and can be
access using the `attr()` function as shown below. The report is automatically
printed out if any of any of the defined cleaning operations were performed
successfully. However, users can access the report using the code below:

```{r eval=TRUE}
# ACCESS THE DATA CLEANING REPORT
report <- attr(cleaned_data, "report")

# SUMMARIZE THE REPORT OBJECT
summary(report)
```

## Specific data cleaning tasks

Certain data cleaning operations are automatically applied to input data. These operations include renaming columns, removing empty rows and columns, removing columns with the same values across all rows, and standardizing date columns. We refer to these operation as the `implicit data cleaning steps`,  which are executed by default.

However, we also provide users with the flexibility to call a specific function if they wish to perform that particular task individually. This approach allows users to have more control over the data cleaning process and to apply additional data cleaning functions as needed.

This setup offers users both convenience and flexibility, as they can benefit from default data cleaning operations while also having the option to customize their data cleaning process according to their specific needs.

### Standardizing Dates

The `standardize_dates()` function provides a comprehensive set of options for converting date columns into a specified format and handling various scenarios, such as different date formats and mixed data types in a column.

The default date format in R is `%Y-%m-%d`. However, it is very common to encounter date values that are written differently from this. Also, there are cases where a column in a data frame contains both values of type `Date`, `character` or others.    
The `standardize_dates()` function offers the possibility to convert date columns into `%Y-%m-%d` format and convert `character` columns into `Date` if the percentage of date values reach a specified threshold. The function needs the following arguments:

1. **data**: A data frame or linelist  (required)   
2. **target_columns**: A vector of the names of the columns to be converted (optional). When        not provided, the function will attempt to detect date columns and perform the                conversion if needed.
3. **format**: A format of the values in the specified columns (optional). If not provided,         the function will attempt to infer the format.
4. **timeframe**: The expected time frame within which the date values should fall. Values          outside of this range will be set to `NA` (optional).
5. **error_tolerance**: The minimum percentage of values of type Date in a character column         needed to convert it into a Date column. Default is 50% i.e. `0.5`.

⚠️ The `error_tolerance` must be used with caution. When it is set, and the  percentage of date values in a character column is less than this threshold, the column will be returned as it is.

This function provides users with the flexibility to standardize date columns in their dataset according to specified requirements, including format, timeframe, and error tolerance for conversion from character to date columns.

```{r eval=TRUE, comment="date_standardisation"}
# STANDARDISE VALUES IN THE 'date_first_pcr_positive_test' COLUMN
test_data <- readRDS(system.file("extdata", "test_df.RDS",
                                 package = "cleanepi"))

head(test_data$date_first_pcr_positive_test)

res <- standardize_dates(
  data            = test_data,
  target_columns  = "date_first_pcr_positive_test",
  format          = NULL,
  timeframe       = NULL,
  error_tolerance = 0.5
)

head(res)
```

This function returns a the input dataset where the (specified) columns are converted into date if the condition is met.

### Standardizing subject IDs

The `check_subject_ids()` function is designed to identify and eliminate rows from the input dataset that don't comply with the expected format for subject IDs. It requires the following parameters:

1. **data**: The input dataset (required).
2. **id_column_name**: The name of the column containing the subject IDs in the dataset             (required).
3. **format**: The expected format for the subject IDs. The function will use this format to        validate the IDs (optional).
4. **prefix**: If subject IDs have a specified prefix, it is used as a value for this               argument. This is optional and can be omitted if there is no prefix.
5. **suffix**: Similarly, if subject IDs have a specified suffix, it is used as a value for         this argument. It can be ignored otherwise.
6. **range**: If there is an expected range of numbers within the subject IDs, define it using       this parameter. It is optional and can be omitted if there is no specific range.

By providing these parameters, the function becomes a versatile tool for data cleaning, ensuring that only rows with subject IDs adhering to the expected format are retained in the dataset. When using the function, make sure to tailor the parameters according to the specific requirements of your dataset and the expected characteristics of the subject IDs.

```{r eval=TRUE, comment="subject_ids_standaedisation"}
# DETECT AND REMOVE INCORRECT SUBJECT IDs
res <- check_subject_ids(
  data           = readRDS(system.file("extdata", "test_df.RDS",
                                       package = "cleanepi")),
  id_column_name = "study_id",
  format         = "PS000P2",
  prefix         = "PS",
  suffix         = "P2",
  range          = c(1L, 100L)
)

# PRINT REPORT
report <- attr(res, "report")

# SUMMARIZE THE REPORT OBJECT
summary(report)
```

The `check_subject_ids()` function returns a list with elements named according to the following conventions:

1. **`r names(res)[1]`**: This element contains either the original input dataset or a subset of it where rows with incorrect IDs have been removed, depending on whether the `remove` parameter is set to `TRUE`.

2. **`r names(res)[2]`**: This element is a list, possibly an augmented report list, where one of its elements is named as **`r names(res$report)`**. This particular element contains a data frame detailing the rows that were detected to have incorrect subject IDs.

To summarize:

- Element 1: Contains the cleaned dataset, either the original or a subset with rows containing bad IDs removed.
- Element 2: Contains a list, possibly with additional information, and one of its elements provides a data frame specifying the rows with incorrect subject IDs.

This structure facilitates easy access to both the cleaned dataset and a detailed report on the detected issues with subject IDs, enhancing the transparency and usability of the function's output.

```{r eval=TRUE}
# DISPLAY ROWS WITH THE INCORRECT SUBJECT IDs
res[["report"]][["incorrect_subject_id"]]
```
### Calculating age in different time scales

The `calculate_age()` function computes the ages of individuals, expressed in years, months, weeks, or days, based on a given date column and a reference date. It requires the following arguments:

1. **`data`** (required): This parameter represents the input dataset containing the relevant information.
   
2. **`date_column_name`** (required): Specify the name of the column containing the birth or relevant dates for which the age is being calculated.
   
3. **`end_date`** (required): This is the reference date used to calculate the age of individuals. The function computes the age relative to this date.
   
4. **`age_in`** (optional): This parameter determines the unit in which the age is expressed. It can be specified as "years", "months", "weeks", or "days". By default, the age is calculated in years if this parameter is not provided.

By utilizing these arguments, the function offers flexibility in determining the age of individuals based on different units and reference dates. It facilitates various analytical tasks where age computation is a necessary component, providing users with the ability to customize the output according to their specific requirements.

```{r eval=TRUE}
# CALCULATE INDIVIDUAL AGE FROM THE `dateOfBirth` COLUMN
age <- calculate_age(data           = readRDS(system.file("extdata", "test_df.RDS",
                                       package = "cleanepi")),
                     target_column = "dateOfBirth", 
                     age_in = "days", 
                     na_strings="-99"
                     )
```

The `calculate_age()` function is designed to enhance the input dataset by adding one or two extra columns containing pertinent age-related information. These additional columns are as follows:

1. **Calculated Age in Specified Unit**: This column contains the calculated age of individuals expressed in the specified unit (years, months, weeks, or days).

2. **Remaining Number of Days**: This optional column indicates the remaining number of days after calculating the age, representing the fractional part of the age calculation. This column is included if needed, providing additional granularity in age representation.

```{r eval=TRUE}
# DISPLAY THE OUTPUT OBJECT
head(age)  # note the last 2 columns
```

### Checking date sequence

The `check_date_sequence()` function verifies the order of sequences in date event columns within a dataset. It ensures that the values in specified date columns follow the desired chronological order. Here are the arguments accepted by the function:

1. **data**: The input dataset that is being analyzed for the correctness of date sequences.
2. **target_columns**: A vector containing the names of date columns of interest. These             columns should be listed in the expected order of occurrence, reflecting the                  chronological sequence of events. For example, `target_columns = c("date_of_infection",       "date_of_admission", "date_of_death")`.
3. **remove_bad_seq**: A Boolean variable with a default value of `FALSE`. If set to `TRUE`,        rows with incorrect date sequences will be removed from the output object. Otherwise,         they will be flagged as erroneous and stored in the report object.

By utilizing these arguments, the `check_date_sequence()` function facilitates the validation of date sequences within a dataset, ensuring data integrity and accuracy for further analysis. Additionally, it offers flexibility by allowing users to choose whether to remove rows with incorrect sequences or store them for further examination in the report object.

```{r eval=TRUE, comment="check_date_order"}
# DETECT ROWS WITH INCORRECT DATE SEQUENCE
res <- check_date_sequence(
  data           = readRDS(system.file("extdata", "test_df.RDS",
                                       package = "cleanepi")),
  target_columns = c("date_first_pcr_positive_test", "date.of.admission"),
  remove_bad_seq = FALSE
)

# PRINT INCORRECT DATE SEQUENCES
report <- attr(res, "report")

# SUMMARIZE THE REPORT OBJECT
summary(report)
```

The `check_date_sequence()` function returns the input dataset or a subset of it without the rows that have incorrect date sequences, depending on whether the `remove_bad_seq` parameter is set to `TRUE`.
It also provides a detailed report highlighting any discrepancies found in the date sequences, enabling users to take appropriate actions. Use the `print_report()` function to display the report made from this operation.

### Finding duplicated rows

The `find_duplicates()` function serves the purpose of identifying duplicated rows within a given dataset. It accepts the following parameters:

1. **data**: The input data frame or linelist.
2. **target_columns**: A vector containing either column names or indexes from which                duplicated rows will be identified. If `NULL` is passed, duplicates will be detected          across all columns of the dataset. Notably, if the input dataset is a `linelist` object,       `target_columns` can be set to `tags` specifically to identify duplicates across the          tagged variables only. 

By leveraging the `find_duplicates()` function with appropriate parameters, users can efficiently pinpoint duplicated rows within their datasets, either across all columns or selectively across tagged variables in a `linelist` object.

```{r eval=TRUE, comment="find_dups"}
# IMPORT A `linelist` DATA
data <- readRDS(system.file("extdata", "test_linelist.RDS",
                            package = "cleanepi"))
head(data)

# SHOW THE TAGGED VARIABLES
linelist::tags(data)

# FIND DUPLICATES ACROSS TAGGED VARIABLES
dups <- find_duplicates(
  data           = data,
  target_columns = "tags"
)
```

Upon execution, the `find_duplicates()` function identifies and returns all duplicated rows within the dataset, either based on all columns or those specified. Additionally, it appends two extra columns to the dataset:

1. `row_id`: This column indicates the row numbers of the duplicated rows from the original input dataset.

2. `group_id`: Each duplicated group is assigned a unique identifier in this column. A duplicated group comprises rows with identical values in the specified columns of interest.

By including these extra columns, users gain insights into the specific rows identified as duplicates and their corresponding group identifiers, enabling efficient analysis and management of duplicated data within the dataset.

```{r eval=TRUE}
# VISUALIZE THE DUPLICATES
head(dups %>% dplyr::select(c(row_id, group_id,
                              as.character(linelist::tags(data)))))
```

### Removing duplicates

To eliminate duplicated rows from a dataset, the `remove_duplicates()` function can be employed. This function internally utilizes the `find_duplicates()` function and expects the following parameters:

1. **data**: Te input dataset from which duplicated rows will be removed.
2. **target_columns**: A vector containing either column names or indexes specifying the            columns from which duplicated rows will be identified. If set to `NULL`, the function         will detect duplicates across all columns. If the input dataset is a `linelist` object,       setting this parameter to `tags` will identify duplicates across the tagged variables         only.
3. **remove**: A numeric vector of the indices of the duplicated rows to be removed. If set to       `NULL`, the function removes duplicates and retains only the first occurrence of the          duplicated rows.
4. **rm_empty_rows**: A Boolean to indicate whether to remove empty rows or not. Default is         `TRUE`
5. **rm_empty_cols**: A Boolean to indicate whether to remove empty columns or not. Default is       `TRUE`
6. **rm_constant_cols**: A Boolean to indicate whether to remove constant columns or not.           Default is `TRUE`


```{r eval=TRUE}
# REMOVE DUPLICATE ACROSS TAGGED COLUMNS ONLY.
res <- remove_duplicates(
  data <- readRDS(system.file("extdata", "test_linelist.RDS",
                            package = "cleanepi")),
  target_columns = NULL,
  remove         = NULL
)
```

Upon execution, the `remove_duplicates()` function returns the input dataset with duplicated rows removed (if found).
The details about the duplicates removal operation are reported as a list attached to the output object. When duplicates are found, this report will contain the following elements:

- **empty_columns**: a vector of empty columns (if found).
- **constant_columns**: a vector of constant columns (if found).
- **duplicated_rows**: a data frame with the detected duplicates.
- **removed_duplicates**: a data frame with the duplicated rows that have been removed.
- **duplicates_checked_from**: a vector of the names of the columns from which duplicates were identified.

By examining these elements within the report, users gain insights into the specific duplicated rows, those that were removed, and the columns used to identify the duplicated, thus facilitating transparency and documentation of the duplicates removal process.

```{r eval=TRUE, comment="print_dups_report"}
# ACCESS THE REPORT
report <- attr(res, "report")

# SUMMARIZE THE REPORT OBJECT
summary(report)
```

Use the `print_report()` function to display the report made from this operation

The output from `find_duplicates()` function can also be passed to `remove_duplicates()` function to specify which duplicated rows to be removed.  

```{r eval=TRUE, comment="find_and_remove_dups"}
# DETECT DUPLICATES FROM TAGGED COLUMNS
dups <- find_duplicates(
  data           = readRDS(system.file("extdata", "test_linelist.RDS",
                                       package = "cleanepi")),
  target_columns = "tags"
)

# REMOVE FIRST OCCURRENCE OF DUPLICATED ROWS
dups_index_to_remove <- dups[["row_id"]][seq(1L, nrow(dups), 2L)]
no_dups <- remove_duplicates(
  data           = readRDS(system.file("extdata", "test_linelist.RDS",
                                       package = "cleanepi")),
  remove         = dups_index_to_remove
)
```

### Dictionary based data substituting

The `clean_using_dictionary()` function offers a convenient way to replace the options in a data frame or linelist with their corresponding values stored in a data dictionary file. The structure of this data dictionary file should adhere to the standards expected by the [matchmaker](https://www.repidemicsconsortium.org/matchmaker/) package, as the `clean_using_dictionary()` function relies on functions from this package.

Here's how the function operates:

- **Inputs**: The function accepts two main inputs:
  1. The input data frame or linelist that contains the options to be replaced.
  2. The corresponding data dictionary file that contains the complete labels for these options. This dictionary file typically includes additional information necessary for understanding the input dataset.

- **Data Dictionary Structure**: The structure of the data dictionary should align with the format expected by the matchmaker package. This format ensures compatibility and seamless integration with the `clean_using_dictionary()` function.

By leveraging the `clean_using_dictionary()` function with a suitable data dictionary, users can effectively replace option values in their datasets with their corresponding labels, enhancing the interpretability and clarity of the data.

```{r eval=TRUE, comment="display_dictionary"}
test_dictionary
```

The `add_to_dictionary()` function is a useful tool for expanding the coverage of a data dictionary by defining options that are present in the input data but not originally included in the dictionary. This function enables users to dynamically update the dictionary to accommodate new values encountered in the dataset.

Here's how the `add_to_dictionary()` function can be utilized:

1. **Identify Undefined Options**: Users can identify options in the input data that are not defined in the existing data dictionary. For instance, in your example, the value `-99` is not defined in the dictionary.

2. **Call `add_to_dictionary()`**: Users can then use the `add_to_dictionary()` function to add the undefined options to the data dictionary. This function facilitates the expansion of the dictionary to include new values encountered in the dataset.

By employing the `add_to_dictionary()` function, users can ensure that the data dictionary remains comprehensive and aligned with the evolving nature of the input dataset, thereby enhancing the accuracy and completeness of data interpretation and analysis. 
In the example below, we add `-99` to our test data dictionary, `test_dictionary`.

```{r eval=TRUE}
## READING IN THE DATA
data <- readRDS(system.file("extdata", "test_df.RDS",
                            package = "cleanepi"))

## ADD THE EXTRA OPTION TO THE DICTIONARY
test_dictionary <- add_to_dictionnary(test_dictionary,
                                      option = "-99",
                                      value  = "unknow",
                                      grp    = "sex",
                                      order  = NULL)
test_dictionary
```


```{r eval=TRUE, comment="dictionary-base_cleaning"}
cleaned_df <- clean_using_dictionary(
  data       = data,
  dictionary = test_dictionary
)

cleaned_df
```


### Calculating age in different time scales

The `calculate_age()` function computes the ages of individuals, expressed in years, months, weeks, or days, based on a given date column and a reference date. It requires the following arguments:

1. **`data`** (required): This parameter represents the input dataset containing the relevant information.
   
2. **`date_column_name`** (required): Specify the name of the column containing the birth or relevant dates for which the age is being calculated.
   
3. **`end_date`** (required): This is the reference date used to calculate the age of individuals. The function computes the age relative to this date.
   
4. **`age_in`** (optional): This parameter determines the unit in which the age is expressed. It can be specified as "years", "months", "weeks", or "days". By default, the age is calculated in years if this parameter is not provided.

By utilizing these arguments, the function offers flexibility in determining the age of individuals based on different units and reference dates. It facilitates various analytical tasks where age computation is a necessary component, providing users with the ability to customize the output according to their specific requirements.

```{r eval=TRUE}
# CALCULATE INDIVIDUAL AGE FROM THE `dateOfBirth` COLUMN
age <- calculate_age(
  data          = readRDS(system.file("extdata", "test_df.RDS",
                                       package = "cleanepi")),
  target_column = "dateOfBirth", 
  age_in        = "days", 
  na_strings    = "-99"
)
```

The `calculate_age()` function is designed to enhance the input dataset by adding one or two extra columns containing pertinent age-related information. These additional columns are as follows:

1. **Calculated Age in Specified Unit**: This column contains the calculated age of individuals expressed in the specified unit (years, months, weeks, or days).

2. **Remaining Number of Days**: This optional column indicates the remaining number of days after calculating the age, representing the fractional part of the age calculation. This column is included if needed, providing additional granularity in age representation.

```{r eval=TRUE}
# DISPLAY THE OUTPUT OBJECT
head(age)  # note the last 2 columns
```






