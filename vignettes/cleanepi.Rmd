---
title: "cleanepi"
output: 
  rmarkdown::html_vignette:
    df_print: "kable"
vignette: >
  %\VignetteIndexEntry{cleanepi}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE} 
knitr::opts_chunk[["set"]](collapse = TRUE, comment = "#>", eval = FALSE,
                           fig.width = 7L, fig.height = 7L,
                           fig.align = "center")
row_id <- group_id <- NULL
```


## An overview

Data cleaning is a critical step of data analysis, especially considering the messy nature of real-world data, which often includes duplicates, errors, incomplete entries, and irrelevant formats. Addressing these issues is essential for producing accurate, reliable, and reproducible results. However, data cleaning can pose a substantial barrier in data analysis due to the time-consuming nature of the process.

**{cleanepi}** is an R package designed specifically to address this challenge by offering tools to clean, curate, and standardize datasets. Tailored specifically for epidemiological data and compatible with data frame-like structures, **{cleanepi}** offers a suite of functions designed to streamline common data cleaning tasks.

This vignette provides a comprehensive guide to the functionalities encapsulated within **{cleanepi}**. It provides users with detailed insights into each function's purpose and practical usage, equipping them with the tools necessary to navigate and manipulate cluttered datasets effectively.

```{r setup, eval=TRUE}
library("cleanepi")
```

## General data cleaning tasks

The main function in **{cleanepi}** is `clean_data()` that can perform the following tasks:

1. Scan the input data to determine the percent of missing, numeric, character, logical and date values in every column of the input data frame.   
2. Clean up column names and convert them to more intuitive formats. This includes many sub-tasks such as replacing a space, dot, or hyphen between two words with underscore; converting camel-cases to snake-cases; substituting foreign characters with their corresponding English characters; and splitting a long word into multiple short words by capital characters within, if any, and connecting them with underscores.   
3. Remove duplicated rows across all columns or some specific columns. This also includes the removal of empty rows and columns as well as constant columns, i.e. columns with the same value across all rows.   
4. Replace missing entries with `NA`. 
5. Check whether the sequence of date events are correct in all rows of the input data.
6. Convert `character` columns into `Date` if the column actually contains values of type `Date` to some extent (default is 50% of the values are `Date`).
7. Detect and remove rows with subject IDs that do not comply with the expected format.
8. Perform dictionary-based cleaning: replace keys in specific columns with their corresponding values stored in a data dictionary file, and replace misspelled values with their correct ones.
9. Convert numbers written in characters into numeric.


```{r eval=TRUE, comment=""}
# IMPORTING THE TEST DATASET
test_data <- readRDS(system.file("extdata", "test_df.RDS",
                                 package = "cleanepi"))
```

```{r eval=TRUE, echo=FALSE}
test_data |>
  kableExtra::kbl() |>
  kableExtra::kable_paper("striped", font_size = 14, full_width = TRUE) |>
  kableExtra::scroll_box(height = "200px", width = "100%",
                         box_css = "border: 1px solid #ddd; padding: 5px; ",
                         extra_css = NULL,
                         fixed_thead = TRUE)
```

```{r eval=TRUE, comment=""}
# SCAN THE DATA
scan_result <- scan_data(test_data)
```

```{r eval=TRUE, echo=FALSE}
scan_result |>
  kableExtra::kbl() |>
  kableExtra::kable_paper("striped", font_size = 14, full_width = TRUE) |>
  kableExtra::scroll_box(height = "200px", width = "100%",
                         box_css = "border: 1px solid #ddd; padding: 5px; ",
                         extra_css = NULL,
                         fixed_thead = TRUE)
```

In **{cleanepi}**, every cleaning operation is encapsulated within a module, with detailed descriptions provided in the package design vignette. Each module also specifies the parameters required for its main function, outlined in the sections below.

In the following chunk, we define a list of cleaning operations that we want to perform on the input data.

```{r eval=TRUE, comment=""}
# PARAMETERS FOR REPLACING MISSING VALUES WITH NA
rm_na <- list(target_columns = NULL, na_strings = "-99")

# PARAMETERS FOR DUBLICATES DETECTION AND REMOVAL
rm_dup <- list(target_columns   = NULL,
               rm_empty_rows    = TRUE,
               rm_empty_cols    = TRUE,
               rm_constant_cols = TRUE)

# PARAMETERS FOR STANDARDING DATES
stdn_date <- list(target_columns  = NULL,
                  error_tolerance = 0.5,
                  format          = NULL,
                  timeframe       = as.Date(c("1973-05-29", "2023-05-29")))

# PARAMETERS FOR STANDARDING SUBJECT IDs
stdn_ids <- list(id_col_name = "study_id",
                 format      = NULL,
                 prefix      = "PS",
                 suffix      = "P2",
                 range       = c(1, 100),
                 remove      = TRUE)

# LAOD THE DATA DICTIONARY
test_dictionary <- readRDS(system.file("extdata", "test_dictionary.RDS",
                                       package = "cleanepi"))

# DEFINE THE LIST OF PARAMETERS
params <- list(
  replace_missing_values  = rm_na,
  remove_duplicates       = rm_dup,
  standardize_date        = stdn_date,
  standardize_subject_ids = stdn_ids,
  dictionary              = test_dictionary
)
```

The `clean_data()` function, as shown below, requires 2 arguments:

1. **data**: A `data.frame` or `linelist`.
2. **params**: A list of parameters that define the cleaning operations to
    be performed.

```{r eval=TRUE, comment=""}
# CLEAN THE INPUT DATA FRAME
cleaned_data <- clean_data(
  data   = test_data,
  params = params
)
```

It returns the cleaned dataset. The report generated from the data cleaning operations is a `list object` that is attached to the cleaned data and can be accessed using the `attr()` function. The report is automatically printed out, and it contains details of each cleaning operation that was performed successfully. However, users can access the report using the code below:

```{r eval=TRUE}
# ACCESS THE DATA CLEANING REPORT
report <- attr(cleaned_data, "report")

# SUMMARIZE THE REPORT OBJECT
summary(report)
```

The report can also be displayed in an HTML format using the `print_report()` function as shown below:

```{r eval=FALSE}
print_report(report)
```

## Specific data cleaning tasks

Certain data cleaning operations are automatically applied to input data. These operations include renaming columns, removing empty rows and columns, removing columns with the same values across all rows, and standardizing date columns. We refer to these operation as the `implicit data cleaning steps`,  which are executed by default.

However, we also provide users with the flexibility to call a specific function if they wish to perform that particular task individually. This approach allows users to have more control over the data cleaning process and to apply additional data cleaning functions as needed.

This setup offers users both convenience and flexibility, as they can benefit from default data cleaning operations while also having the option to customize their data cleaning process according to their specific needs.

### Standardizing Dates

The `standardize_dates()` function provides a comprehensive set of options for converting date columns into a specified format and handling various scenarios, such as different date formats and mixed data types in a column.

The default date format in R is `%Y-%m-%d` (the ISO format). However, it is very common to encounter date values that are written differently from this. Also, there are cases where a column in a data frame contains both values of type `Date`, `character` or others.   

The `standardize_dates()` function offers the possibility to convert date columns into `%Y-%m-%d` format and convert `character` columns into `Date` if the percentage of date values reach a specified threshold. The function needs the following arguments:

1. **data**: A data frame or linelist  (required).   
2. **target_columns**: A vector of the names of the columns to be converted (optional). When not provided, the function will attempt to detect date columns and perform the  conversion if needed.
3. **format**: A format of the values in the specified columns (optional). If not provided, the function will attempt to infer the format.
4. **timeframe**: The expected time frame within which the date values should fall. Values  outside of this range will be set to `NA` (optional).
5. **error_tolerance**: The minimum percentage of values of type Date in a character column  needed to convert it into a Date column. Default is 50% i.e. `0.5`.

⚠️ The `error_tolerance` must be used with caution. When it is set, and the  percentage of date values in a character column is less than this threshold, the column will be returned as it is.

This function provides users with the flexibility to standardize date columns in their dataset according to specified requirements, including format, timeframe, and error tolerance for conversion from character to date columns.

```{r eval=TRUE, comment="date_standardisation"}
# STANDARDISE VALUES IN THE 'date_first_pcr_positive_test' COLUMN
test_data <- readRDS(system.file("extdata", "test_df.RDS",
                                 package = "cleanepi"))

head(test_data$date_first_pcr_positive_test)

res <- standardize_dates(
  data            = test_data,
  target_columns  = "date_first_pcr_positive_test",
  format          = NULL,
  timeframe       = NULL,
  error_tolerance = 0.5
)
```

This function returns a the input dataset where the (specified) columns are converted into date if the condition is met.

```{r echo=FALSE, eval=TRUE}
res |>
  kableExtra::kbl() |>
  kableExtra::kable_paper("striped", font_size = 14, full_width = TRUE) |>
  kableExtra::scroll_box(height = "200px", width = "100%",
                         box_css = "border: 1px solid #ddd; padding: 5px; ",
                         extra_css = NULL,
                         fixed_thead = TRUE)
```

### Standardizing subject IDs

#### Detecting and remove incorrect subject ids

The `check_subject_ids()` function is designed to identify and eliminate rows from the input dataset that don't comply with the expected format for subject IDs. It requires the following parameters:

1. **data**: A data frame or linelist (required).
2. **id_column_name**: The name of the column containing the subject IDs in the dataset (required).
3. **format**: The expected format for the subject IDs. The function will use this format to validate the IDs (optional).
4. **prefix**: A string. If subject IDs have a specified prefix, it is used as a value for this argument. This is optional and can be omitted if there is no prefix.
5. **suffix**: A string. If subject IDs have a specified suffix, it is used as a value for this argument. It can be ignored otherwise.
6. **range**: A vector of two elements. If there is an expected range of numbers within the subject IDs, define it using  this parameter. It is optional and can be omitted if there is no specific range.
7. **remove**: A logical that determines whether to remove the incorrect subject IDs or not. By default, the wrong ids are detected and reported, and replaced using the `correct_subject_ids()` function.

By providing these parameters, the function becomes a versatile tool for data cleaning, ensuring that only rows with subject IDs adhering to the expected format are retained in the dataset. When using the function, make sure to tailor the parameters according to the specific requirements of your dataset and the expected characteristics of the subject IDs.

```{r eval=TRUE, comment="subject_ids_standaedisation"}
# DETECT AND REMOVE INCORRECT SUBJECT IDs
res <- check_subject_ids(
  data           = readRDS(system.file("extdata", "test_df.RDS",
                                       package = "cleanepi")),
  id_column_name = "study_id",
  format         = "PS000P2",
  prefix         = "PS",
  suffix         = "P2",
  range          = c(1L, 100L),
  remove         = TRUE
)

# EXTRACT REPORT
report <- attr(res, "report")

# SUMMARIZE THE REPORT OBJECT
summary(report)
```

The `check_subject_ids()` function returns the input dataset or a subset of a subset of the input data where rows with incorrect IDs have been removed (if `remove = TRUE`).

In addition to detecting wrong subject IDs, the function will also look for missing and duplicated IDs. As the result of this, the report made from this operation might contain two extra elements: **missing_ids** (a vector of row indexes where there is a missing IDs) and **duplicated_ids** (a data frame of rows with the duplicated IDs). Use the `print_report()` function to display the report made from this operation.

#### Detecting and correct wrong subject ids

When the user needs to find out the incorrect subject ids in order to correct, the `remove` argument of the `check_subject_ids()` should be set to `FALSE`.
This allows to subsequently use the `correct_subject_ids()` to replace non complying ids with the correct ones. The function requires a data frame with the following two columns:

1. **from**: a column with the wrong subject ids,
2. **to**: a column with the values to be used to substitute the incorrect ids.

```{r eval=TRUE, comment="correct ids"}
# IMPORT THE INPUT DATA
data <- readRDS(system.file("extdata", "test_df.RDS", package = "cleanepi"))

# DETECT THE INCORRECT SUBJECT IDS
dat <- check_subject_ids(
  data           = data,
  id_column_name = "study_id",
  format         = NULL,
  prefix         = "PS",
  suffix         = "P2",
  range          = c(1L, 100L),
  remove         = FALSE
)

# GENERATE THE CORRECTION TABLE
correction_table <- data.frame(
  from = c("P0005P2", "PB500P2", "PS004P2-1"),
  to   = c("PB005P2", "PB050P2", "PS004P2")
)

# perform the correction
dat <- correct_subject_ids(
  data             = dat,
  id_column_name   = "study_id",
  correction_table = correction_table
)
```


### Checking date sequence

The `check_date_sequence()` function verifies the order of sequences in date event columns within a dataset. It ensures that the values in specified date columns follow the desired chronological order. Here are the arguments accepted by the function:

1. **data**: A data frame or linelist (required).
2. **target_columns**: A vector containing the names of date columns of interest. These columns should be listed in the expected order of occurrence, reflecting the chronological sequence of events. For example, `target_columns = c("date_of_infection", "date_of_admission", "date_of_death")`.
3. **remove**: A Boolean variable with a default value of `FALSE`. If set to `TRUE`, rows with incorrect date sequences will be removed from the output object. Otherwise, they will be flagged as erroneous and stored in the report object.

By utilizing these arguments, the `check_date_sequence()` function facilitates the validation of date sequences within a dataset, ensuring data integrity and accuracy for further analysis. Additionally, it offers flexibility by allowing users to choose whether to remove rows with incorrect sequences or store them for further examination in the report object.

```{r eval=TRUE, comment="check_date_order"}
# DETECT ROWS WITH INCORRECT DATE SEQUENCE
res <- check_date_sequence(
  data           = readRDS(system.file("extdata", "test_df.RDS",
                                       package = "cleanepi")),
  target_columns = c("date_first_pcr_positive_test", "date.of.admission"),
  remove         = FALSE
)

# EXTRACT THE REPORT
report <- attr(res, "report")

# SUMMARIZE THE REPORT OBJECT
summary(report)
```

The `check_date_sequence()` function returns the input dataset or a subset of it without the rows that have incorrect date sequences, depending on whether the `remove_bad_seq` parameter is set to `TRUE`.
It also provides a detailed report highlighting any discrepancies found in the date sequences, enabling users to take appropriate actions. Use the `print_report()` function to display the report made from this operation.

### Converting character columns into numeric

In certain scenarios, the input data contains columns where the number are written in letters. For instance, the ages of a study participants can be written in letters. Similarly, a column can contain values written in both numbers and letters (an age column where some values are written in numbers and others in letters). The `convert_to_numeric()` function offers the framework to convert all numbers written in letters from a given column into numeric. It takes the following arguments:

1. **data**: A data frame or linelist (required).
2. **target_columns**: A vector containing the names of the columns of interest. When dealing with a linelist, this can be set to `linelist_tags` if the tagged columns are the one to be converted into numeric. When `target_columns = NULL`, the function uses the output form the `scan_data()` function to identify the columns where the proportion of numeric values is at least twice as the percentage of character values. Those columns will be the columns of interest interest and the character values in them will be converted into numeric. 
Note that any string in such column that can not be converted into numeric will be set to `NA` in the resulting data.

```{r eval=TRUE, comment="check_date_order"}
# CONVERT THE 'age' COLUMN IN THE TEST LINELIST DATA
dat <- readRDS(system.file("extdata", "messy_data.RDS", package = "cleanepi"))
head(dat$age, 10L)
dat <- convert_to_numeric(dat, target_columns = "age")
head(dat$age, 10L)
```

### Finding duplicated rows

The `find_duplicates()` function serves the purpose of identifying duplicated rows within a given dataset. It accepts the following parameters:

1. **data**: The input data frame or linelist.
2. **target_columns**: A vector containing either column names or indexes from which  duplicated rows will be identified. If `NULL` is passed, duplicates will be detected  across all columns of the dataset. Notably, if the input dataset is a `linelist` object, `target_columns` can be set to `tags` specifically to identify duplicates across the tagged variables only. 

By leveraging the `find_duplicates()` function with appropriate parameters, users can efficiently pinpoint duplicated rows within their datasets, either across all columns or selectively across tagged variables in a `linelist` object.

```{r eval=TRUE, comment=""}
# IMPORT A `linelist` DATA
data <- readRDS(system.file("extdata", "test_linelist.RDS",
                            package = "cleanepi"))

# SHOW THE TAGGED VARIABLES
linelist::tags(data)

# FIND DUPLICATES ACROSS ALL COLUMNS EXCEPT THE SUBJECT IDs COLUMN
all_columns    <- names(data)
target_columns <- all_columns[all_columns != "id"]
dups           <- find_duplicates(data           = data,
                                  target_columns = target_columns)

# FIND DUPLICATES ACROSS TAGGED VARIABLES
dups <- find_duplicates(
  data           = data,
  target_columns = "linelist_tags"
)
```

Upon execution, the `find_duplicates()` function identifies all duplicated rows either based on all columns or those specified, and stores them in the report. In addition to the existing columns, it appends two extra columns to the dataset:

1. `row_id`: Contains  indexes of the duplicated rows from the original input dataset.

2. `group_id`: Contains unique identifiers assigned to each duplicated group, which is defined as a set of rows sharing identical values in the designated columns of interest.

By including these extra columns, users gain insights into the specific rows identified as duplicates and their corresponding group identifiers, enabling efficient analysis and management of duplicated data within the dataset.

```{r eval=TRUE}
# VISUALIZE THE DUPLICATES
report     <- attr(dups, "report")
duplicates <- report$duplicated_rows
duplicates |>
  kableExtra::kbl() |>
  kableExtra::kable_paper("striped", font_size = 14, full_width = TRUE) |>
  kableExtra::scroll_box(height = "200px", width = "100%",
                         box_css = "border: 1px solid #ddd; padding: 5px; ",
                         extra_css = NULL,
                         fixed_thead = TRUE)
```

### Removing duplicates

To eliminate duplicated rows from a dataset, the `remove_duplicates()` function can be employed. This function internally utilizes the `find_duplicates()` function and expects the following parameters:

1. **data**: A data frame of the input dataset from which duplicated rows will be removed.
2. **target_columns**: A vector containing either column names or indexes specifying the  columns from which duplicated rows will be identified. If set to `NULL`, the function will detect duplicates across all columns. If the input dataset is a `linelist` object, setting this parameter to `tags` will identify duplicates across the tagged variables only.
3. **remove**: A numeric vector of the indices of the duplicated rows to be removed. If set to  `NULL`, the function removes duplicates and retains only the first occurrence of the   duplicated rows.
4. **rm_empty_rows**: A Boolean to indicate whether to remove empty rows or not. The default is `TRUE`
5. **rm_empty_cols**: A Boolean to indicate whether to remove empty columns or not. The default is `TRUE`
6. **rm_constant_cols**: A Boolean to indicate whether to remove constant columns or not. The default is `TRUE`


```{r eval=TRUE}
# REMOVE DUPLICATE ACROSS TAGGED COLUMNS ONLY.
res <- remove_duplicates(
  data           = readRDS(system.file("extdata", "test_linelist.RDS",
                                       package = "cleanepi")),
  target_columns = NULL,
  remove         = NULL
)
```

Upon execution, the `remove_duplicates()` function returns the input dataset with duplicated rows removed (if found).
The details about the duplicates removal operation are reported as a list attached to the output object. When duplicates are found, this report will contain the following elements:

- **empty_columns**: A vector of empty columns (if found).
- **constant_columns**: A vector of constant columns (if found).
- **duplicated_rows**: A data frame with the detected duplicates.
- **removed_duplicates**: A data frame with the duplicated rows that have been removed.
- **duplicates_checked_from**: A vector of the names of the columns from which duplicates were identified.

By examining these elements within the report, users gain insights into the specific duplicated rows, those that were removed, and the columns used to identify the duplicated, thus facilitating transparency and documentation of the duplicates removal process.

```{r eval=TRUE, comment=""}
# ACCESS THE REPORT
report <- attr(res, "report")

# SUMMARIZE THE REPORT OBJECT
summary(report)
```

Use the `print_report()` function to display the report made from this operation

The output from `find_duplicates()` function can also be passed to `remove_duplicates()` function to specify which duplicated rows to be removed.  

```{r eval=TRUE, comment="find_and_remove_dups"}
# DETECT DUPLICATES FROM TAGGED COLUMNS
dups <- find_duplicates(
  data           = readRDS(system.file("extdata", "test_linelist.RDS",
                                       package = "cleanepi")),
  target_columns = "linelist_tags"
)

# EXTRACT THE DUPLICATES
report     <- attr(dups, "report")
duplicates <- report$duplicated_rows

# REMOVE FIRST OCCURRENCE OF DUPLICATED ROWS
dups_index_to_remove <- duplicates[["row_id"]][seq(1L, nrow(dups), 2L)]
dups_index_to_remove <- dups_index_to_remove[!is.na(dups_index_to_remove)]
no_dups <- remove_duplicates(
  data           = readRDS(system.file("extdata", "test_linelist.RDS",
                                       package = "cleanepi")),
  target_columns = "linelist_tags",
  remove         = dups_index_to_remove
)

# KEEP SPECIFIC DUPLICATED ROWS
no_dups <- remove_duplicates(
  data           = readRDS(system.file("extdata", "test_linelist.RDS",
                                       package = "cleanepi")),
  target_columns = "linelist_tags",
  remove         = -c(33, 55)
)
```

### Dictionary based data substituting

The `clean_using_dictionary()` function offers a convenient way to replace the options in a data frame or linelist with their corresponding values stored in a data dictionary file. The function expects the following arguments:

1. **data**: The input data frame or linelist that contains the options to be replaced.
2. **dictionary**: The data frame with the data dictionary that contains the complete labels for these options. The structure of this data dictionary file should adhere to the standards expected by the [matchmaker](https://www.repidemicsconsortium.org/matchmaker/)  package, as the `clean_using_dictionary()` function relies on functions from this   package.

```{r eval=TRUE, echo=FALSE}
test_dictionary |>
  kableExtra::kbl() |>
  kableExtra::kable_paper("striped", font_size = 14, full_width = TRUE)
```

The `add_to_dictionary()` function is a useful tool for expanding the coverage of a data dictionary by defining options that are present in the input data but not originally included in the dictionary. This function enables users to dynamically update the dictionary to accommodate new values encountered in the dataset. In addition to the current data dictionary the function takes the arguments defined below:

**option, value, grp, order**: the values for the options to be added in the data dictionary. The example below shows how this function is used.

By employing the `add_to_dictionary()` function, users can ensure that the data dictionary remains comprehensive and aligned with the evolving nature of the input dataset, thereby enhancing the accuracy and completeness of data interpretation and analysis. 
In the example below, we add `-99` to our test data dictionary, `test_dictionary`.

```{r eval=TRUE}
# READING IN THE DATA
data <- readRDS(system.file("extdata", "test_df.RDS",
                            package = "cleanepi"))

# ADD THE EXTRA OPTION TO THE DICTIONARY
test_dictionary <- add_to_dictionary(test_dictionary,
                                      option = "-99",
                                      value  = "unknow",
                                      grp    = "sex",
                                      order  = NULL)
```

```{r eval=TRUE, echo=FALSE}
test_dictionary |>
  kableExtra::kbl() |>
  kableExtra::kable_paper("striped", font_size = 14, full_width = TRUE)
```


```{r eval=TRUE, comment=""}
cleaned_df <- clean_using_dictionary(
  data       = data,
  dictionary = test_dictionary
)
```

```{r eval=TRUE, echo=FALSE}
cleaned_df |>
  kableExtra::kbl() |>
  kableExtra::kable_paper("striped", font_size = 14, full_width = TRUE) |>
  kableExtra::scroll_box(height = "200px", width = "100%",
                         box_css = "border: 1px solid #ddd; padding: 5px; ",
                         extra_css = NULL,
                         fixed_thead = TRUE)
```

### Calculating age in different time scales

The `calculate_age()` function computes the ages of individuals, expressed in years, months, weeks, or days, based on a given date column and a reference date. It requires the following arguments:

1. **data**: The input dataset (required).
2. **target_column**: A vector of the name of the column containing the birth or relevant  dates for which the age is being calculated (required).
3. **end_date**: This is the reference date used to calculate the age of individuals (required). The function computes the age relative to this date. The default value is today's date (`Sys.Date()`)
> The format required for this argument is `%Y-%m-%d` ("2024-12-31" for 31st of December 2024).

4. **age_in**: This parameter determines the unit in which the age is expressed (required). It  can be specified as "years", "months", "weeks", or "days". By default, the age is calculated in years if this parameter is not provided.
5. **age_column_name**: A string for the name of the age column added to the input data. The default is `age_in_*` where `*` represents the unit specified in the 'age_in' argument.
6. **age_remainder_unit**: A parameter used to determine the number of the remaining days (remainder_days) or weeks (remainder_weeks) or months (remainder_months), depending on the value of the 'age_remainder_unit' parameter, after calculating the age.

With these arguments, the function offers flexibility in determining the age of individuals based on different units and reference dates. It facilitates various analytics tasks where age computation is a necessary component, providing users with the ability to customize the output according to their specific requirements.

```{r eval=TRUE}
# IMPORT THE INPUT DATA
data <- readRDS(system.file("extdata", "test_df.RDS", package = "cleanepi"))

# REPLACE MISSING VALUES IN TARGET COLUMNS WITH `NA`
data <- replace_missing_values(data           = data,
                               target_columns = "dateOfBirth",
                               na_strings     = "-99")

# calculate_age() EXPECTS DATE VALUES IN ISO FORMAT.
data <- standardize_dates(data            = data,
                          target_columns  = "dateOfBirth",
                          error_tolerance = 0.0)

# CALCULATE INDIVIDUAL AGE IN YEARS FROM THE 'dateOfBirth' COLUMN AND SEND THE
# REMAINDER IN MONTHS
age <- calculate_age(
  data               = data,
  target_column      = "dateOfBirth",
  end_date           = Sys.Date(),
  age_in             = "years",
  age_remainder_unit = "months"
)

# USING THE dplyr SYNTHAX
data <- readRDS(system.file("extdata", "test_df.RDS", package = "cleanepi"))
age  <- data |>
  replace_missing_values(target_columns = "dateOfBirth",
                         na_strings     = "-99") |>
  standardize_dates(target_columns  = "dateOfBirth", error_tolerance = 0.0) |>
  calculate_age(target_column      = "dateOfBirth",
                end_date           = Sys.Date(),
                age_in             = "years",
                age_remainder_unit = "months")
```

The `calculate_age()` function augments the input dataset by adding one or two extra columns containing age-related information. These additional columns are as follows:

1. **Calculated age in specified scale**:  Contains the calculated age of individuals expressed in the specified unit (years, months, weeks, or days).

2. **Remaining number of days**:  Indicates the remaining number of days after calculating the age, representing the fractional part of the age calculation. This column is included if needed, and provides additional granularity in age representation.

```{r eval=TRUE, echo=FALSE}
# DISPLAY THE OUTPUT OBJECT
age |>
  kableExtra::kbl() |>
  kableExtra::kable_paper("striped", font_size = 14, full_width = TRUE) |>
  kableExtra::scroll_box(height = "200px", width = "100%",
                         box_css = "border: 1px solid #ddd; padding: 5px; ",
                         extra_css = NULL,
                         fixed_thead = TRUE)
```

## Printing the report

```{r echo=TRUE, eval=FALSE}
print_report(
  data             = data,
  report_title     = "{cleanepi} data cleaning report",
  output_directory = ".",
  output_filename  = "cleaning_report",
  format           = "html",
  print            = TRUE
)
```
