---
title: "Package Design vignette for {cleanepi}"
output:
  rmarkdown::html_vignette:
    df_print: "kable"
vignette: >
  %\VignetteIndexEntry{Package Design vignette for {cleanepi}}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment  = "#>"
)
```

## Concept and motivation

In this document, we will outline the design decisions that have steered the development strategies of the {cleanepi} R package, along with the rationale behind each decision and the potential advantages and disadvantages associated with them.

Data cleaning is an important phase for ensuring the efficacy of downstream analysis. The procedures entailed in the cleaning process may differ based on the data type and research objectives. Nonetheless, certain steps can be applied universally across diverse data types, irrespective of their origin.

## Design decisions

The {cleanepi} R package is designed to offer functional programming-style data cleansing tasks. To streamline the organization of data cleaning operations, we have categorized them into distinct groups referred to as **modules**. These modules are based on overarching goals derived from commonly anticipated data cleaning procedures. Each module features a primary function along with additional helper functions tailored to accomplish specific tasks. It's important to note that only the main function of each module will be exported. This deliberate choice empowers users to execute individual cleaning tasks as needed, enhancing flexibility and usability.

```{r echo=FALSE}
knitr::include_graphics(file.path("..", "man", "figures",
                                  "cleanepi_design_diagram.drawio.png"))
```

At the core of {cleanepi}, the pivotal function `clean_data()` serves as a wrapper encapsulating all the modules, as illustrated in Figure @fig:1. This function is intended to be the primary entry point for users seeking to cleanse their data. We have categorized cleaning actions into two main types: **implicit** and **explicit**. Implicit actions are executed by default, regardless of user specifications; while explicit actions are performed only upon user request.

In addition, this package also has two surrogate functions:

1. `scan_data()`: This function enables users to assess the data types present in each column of their dataset.
2. `print_report()`: By utilizing this function, users can visualize the report generated from each applied cleaning task, facilitating transparency and understanding of the data cleaning process.

## Scope

{cleanepi} is an R package  crafted to clean, curate, and standardize tabular datasets, with a particular focus on epidemiological data. In the architecture of {cleanepi}, the data cleaning operations are categorized into modules, each provides specific data cleaning task. The modules in the current version of {cleanepi} encompass:

- Standardization of column names
- Removal of duplicates
- Replacement of missing values with `NA`
- Standardization of subject IDs
- Standardization of date values
- Replacement of existing values with predefined ones (dictionary based substitutions)
- Conversion of values when necessary
- Verification of the sequence order of date-events
- Transformation of select columns.

By compartmentalizing these operations into modules, {cleanepi} offers users a systematic and adaptable framework to address diverse data cleaning needs, especially within the realm of epidemiological datasets. 

 

## Input

The primary functions of the modules, as well as the core function `clean_data`, accept input in the form of a `data.frame` or `linelist`. This offers flexibility for users regarding where they want to position {ceanepi} within the R package ecosystem for epidemic analysis pipelines, either to clean data before or after converting it to a `linelist`.

In addition to the target dataset, the core function `clean_data()` accepts a `list` of operations to be executed on the dataset. It subsequently invokes the primary functions specified for each module. 


## Output

Both the primary functions of the modules and the core function `clean_data` return an object of type `data.frame` or `linelist`. The report generated from all cleaning tasks is appended to this `data.frame` as an attribute, which can be accessed using the `attr()` function in base R.


### Modules in {cleanepi}
In this section, we provide a detailed description of the way that every module is built.

**1. Standardization of column names**

This module is designed to standardize the style and format of column names within the target dataset, offering users the flexibility to specify a subset of focal columns to preserve in their original format.

- **Main function:** `standardize_column_names()`
- **Input:** 
  - A `data.frame` or `linelist` object.
  - Optionally, a `vector` of focal column names. If not provided, all columns will undergo standardization.
- **Output:** 
  - The input object with standardized column names.
- **Report:** 
  - A two-column table displaying the initial and current column names for each updated column in the original dataset.
- **Mode:** 
  - Implicit.

By incorporating the `standardize_column_names()` function, {cleanepi} streamlines the process of ensuring consistency and clarity in column naming conventions, thereby enhancing the overall organization and readability of the dataset.
  
**2. Removal of duplicates**

This module is designed to identify and eliminate duplicate rows, columns, and constant columns within the dataset.

- **Main function:** `remove_duplicates()`
- **Input:** Accepts a `data.frame` or `linelist` object, along with optional parameters:
  - Vector of target columns (default is to consider all columns)
  - Option to remove empty rows (all rows by default)
  - Option to remove empty columns (all columns by default)
  - Option to remove constant columns (all constant columns by default)
- **Output:** Returns the input object after applying the specified operations.
- **Report:**
  - A two-column table showcasing items and their values. Items include empty rows, empty columns, and constant columns.
  - A table detailing the removed duplicates.
- **Mode:** Operates implicitly.

Through the `remove_duplicates()` function, users can streamline their dataset by eliminating redundant rows, columns, and constant values, thus enhancing data integrity and analysis efficiency.
  
**3. Replacement missing values with `NA`**

This module aims to standardize and unify the representation of missing values within the dataset.

- **Main function:** `replace_missing_char()`
- **Input:** Accepts a `data.frame` or `linelist` object, along with:
  - A `vector` of column names (if not provided, the operation is performed across all columns)
  - A string specifying missing values (default value is null)
- **Output:** Returns the input object with all missing values represented as `NA`.
- **Report:** Generates a three-column table featuring index, column, and value for each missing item in the dataset.
- **Mode:** Operates implicitly.

By utilizing the `replace_missing_char()` function, users can ensure consistency in handling missing values across their dataset, facilitating accurate analysis and interpretation of the data.
  
**4. Standardization of date values**

This module is dedicated to standardizing the format of date-value columns and ensuring that all dates fall within a specified timeframe.

- **Main function:** `standardize_dates()`
- **Input:** Accepts a `data.frame` or `linelist` object, along with:
  - A `vector` of targeted date columns (automatically determined if not provided)
  - Tolerance threshold (default value is 50%)
  - Format (default value is NULL)
  - Timeframe (default value is null)
- **Output:** Returns the input object with standardized date values in the format of *yyyy-mm-dd*.
- **Report:**
  - A two-column table listing the columns where date values were standardized.
  - A three-column table featuring index, column name, and values that fall outside the specified timeframe.
- **Mode:** Operates implicitly.

By employing the `standardize_dates()` function, users can ensure uniformity and coherence in date formats across their dataset, while also validating the temporal integrity of the data within the defined timeframe.

**5. Standardization of subject IDs**

This module is tailored to verify whether the values in the column uniquely identifying subjects adhere to a consistent format.

- **Main function:** `check_subject_ids()`
- **Input:** Accepts a `data.frame` or `linelist` object, along with:
  - The name of the ID column
  - Strings for prefix, suffix, and numerical range within the IDs
- **Output:** Returns the input object with standardized subject IDs.
- **Report:** Generates a two-column table featuring index and value of each subject ID that deviates from the expected format.
- **Mode:** Operates explicitly.

By utilizing the `check_subject_ids()` function, users can ensure uniformity in the format of subject IDs, facilitating accurate tracking and analysis of individual subjects within the dataset.

**6. Dictionary based substitution **

This module facilitates dictionary-based substitution, which involves replacing existing values with predefined ones. It standardizes entries in specific columns to certain values, such as substituting 1 with "male" and 2 with "female" in a gender column. It also interoperate seamlessly with the `get_meta_data()` function from {readepi} R package.

- **Main function:** `clean_using_dictionary()`
- **Input:** Accepts a `data.frame` or `linelist` object, along with a data dictionary featuring the following column names: options, values, column, and order.
- **Output:** Returns the input object where the specified options are replaced by their corresponding values.
- **Report:** Generates a three-column table with index, column, and value for each unexpected value encountered in a targeted column.
- **Mode:** Operates explicitly.

By leveraging the `clean_using_dictionary()` function, users can streamline and standardize the values within specific columns based on predefined mappings, enhancing consistency and accuracy in the dataset.

Note that the `clean_using_dictionary()` function will return a warning when it
detects unexpected values in the target columns specified in the data dictionary.
The unexpected values can be added to the data dictionary using the `add_to_dictionary()` function.

**7. Conversion of values when necessary **

This module is designed to convert numbers written in letters to numerical values, ensuring interoperability with the {numberize} package.

- **Main function:** `convert_to_numeric()`
- **Input:** Accepts a `data.frame` or `linelist` object, along with:
  - A vector of column names to be converted into numeric
  - The output of the `scan_data()` function
- **Output:** Returns the input object with values in the target columns converted into numeric format.
- **Report:** Generates a three-column table with index, column, and value for each unrecognized value in the dataset (strings that could not be converted into numeric).
- **Mode:** Operates explicitly.

By employing the `convert_to_numeric()` function, users can seamlessly transform numeric representations written in letters into numerical values, ensuring compatibility with the {numberize} package and promoting accuracy in numerical analysis.
  
Note that `convert_to_numeric()` will issue a warning for unexpected values and return them in the report.

**8. Verification of the sequence of date-events **

This module provides functions to verify whether the sequence of date events aligns with expectations. For instance, it can flag rows where the date of admission to the hospital precedes the individual's date of birth.

- **Main function:** `check_date_sequence()`
- **Input:** Accepts a `data.frame` or `linelist` object, along with:
  - A vector of date column names to be considered
  - A logical value to specify whether to remove the incorrect rows from the input data or not
- **Output:** Returns the input object with incorrect rows removed if specified.
- **Report:** Generates a table listing the incorrect rows from the specified columns.
- **Mode:** Operates explicitly.

By using the `check_date_sequence()` function, users can systematically validate and ensure the coherence of date sequences within their dataset, promoting accuracy and reliability in subsequent analyses.

**9. Transformation of select columns**

This module is dedicated to performing various specialized operations related to epidemiological data analytics, and it currently includes the following function:

- **Main function:** `calculate_age()`
- **Input:** Accepts a `data.frame` or `linelist` object, along with:
  - The name of the column of interest
  - The reference date
  - The time unit (possible values are days, weeks, months, or years)
- **Output:** Returns the input object with clean data and an additional age column with values in the specified time unit.
- **Report:** None.
- **Mode:** Operates explicitly.

By leveraging the `calculate_age()` function, users can efficiently compute and integrate age-related information into their epidemiological dataset based on user-defined parameters, enhancing the analytical capabilities of the dataset.

### Surrogate functions

1. `scan_data()`: This function is designed to generate a quick summary of the dataset, offering insights into the composition of each column. It calculates the percentage of values belonging to different data types such as character, numeric, missing, logical, and date. This summary can help analysts and data scientists understand the structure and content of the dataset at a glance.

2. `print_report()`: This function is responsible for displaying reports detailing the cleaning operations executed on the dataset. It likely presents information about the data cleaning processes performed, such as handling missing values, correcting data types, removing duplicates, and any other transformations applied to ensure data quality and integrity.

These surrogate functions play crucial roles in the data analysis and cleaning workflow, providing valuable information and documentation about the dataset's characteristics and the steps taken to prepare it for analysis or modeling. 

## Dependencies

The modules and surrogate functions will depend mainly on the following packages:   

  [{numberize}](https://github.com/epiverse-trace/numberize),
  [{dplyr}](https://CRAN.R-project.org/package=dplyr),
  [{maggritr}](https://CRAN.R-project.org/package=maggritr),
  [{linelist}](https://CRAN.R-project.org/package=linelist),
  [{janitor}](https://CRAN.R-project.org/package=janitor),
  [{matchmaker}](https://CRAN.R-project.org/package=matchmaker),
  [{lubridate}](https://CRAN.R-project.org/package=dplyr),
  [{epitrix}](https://CRAN.R-project.org/package=epitrix),
  [{arsenal}](https://CRAN.R-project.org/package=arsenal),
  [{naniar}](https://CRAN.R-project.org/package=naniar),
  [{glue}](https://CRAN.R-project.org/package=glue),
  [{stringr}](https://CRAN.R-project.org/package=stringr),
  [{snakecase}](https://CRAN.R-project.org/package=snakecase),
  [{readr}](https://CRAN.R-project.org/package=readr), and
  [{R.utils}](https://CRAN.R-project.org/package=R.utils).
  
The functions will require all other packages that needed in the package development process including:    

  [{checkmate}](https://CRAN.R-project.org/package=checkmate),
  [{kableExtra}](https://CRAN.R-project.org/package=kableExtra),
  [{bookdown}](https://CRAN.R-project.org/package=bookdown),
  [{rmarkdown}](https://CRAN.R-project.org/package=rmarkdown),
  [{testthat}](https://CRAN.R-project.org/package=testthat) (>= 3.0.0),
  [{knitr}](https://CRAN.R-project.org/package=knitr),
  [{lintr}](https://CRAN.R-project.org/package=lintr)

## Contribute

There are no special requirements to contributing to {cleanepi}, please follow the [package contributing guide](https://github.com/epiverse-trace/.github/blob/main/CONTRIBUTING.md).
